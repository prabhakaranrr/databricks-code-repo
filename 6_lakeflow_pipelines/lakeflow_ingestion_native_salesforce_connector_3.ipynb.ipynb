{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbcc213b-a122-4063-912b-5b9a53ba5446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**A fully managed, connector-based ingestion pipeline that loads SaaS data into the Bronze layer of the Databricks Lakehouse with built-in incremental sync.<br>**\n",
    "Here we are using Lakeflow Native Salesforce ingestion, which provides managed, incremental CDC ingestion from Salesforce objects into Bronze Delta tables governed by Unity Catalog, without writing custom ingestion code\n",
    "\n",
    "- Salesforce account creation\n",
    "- Creating Salesforce connection in Databricks\n",
    "- Creating Lakeflow Ingestion Pipeline\n",
    "- Selecting Unity Catalog target\n",
    "- Scheduling & notifications\n",
    "- Incremental ingestion validation\n",
    "\n",
    "Highlights:\n",
    "- Uses Salesforce system fields (LastModifiedDate)\n",
    "- Maintains ingestion state internally\n",
    "- Tracks offsets per object\n",
    "- Writes optimized Delta files\n",
    "- Guarantees idempotency\n",
    "\n",
    "**Lakeflow Native Connector** Lakeflow connectors are Databricks-managed ingestion connectors that directly connect to operational systems and SaaS platforms. They reduce custom ingestion code and are natively governed.\n",
    "\n",
    "**Salesforce Ingestion using Lakeflow Native Connector**\n",
    "- Generate Free Account & security token from Salesforce\n",
    "- Create Salesforce Connection in Databricks\n",
    "- Configure Salesforce Objects for Ingestion\n",
    "- Follow the detailed instruction given below to achieve the ingestion.\n",
    "\n",
    "Refer the slide#77 in the<br>\n",
    "https://docs.google.com/presentation/d/17YwwoAS2CBbUrwmOaH8R3vcKGVTWK-H_/edit?usp=drive_link&ouid=112811125782165229325&rtpof=true&sd=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "025eaa19-91e3-469a-bf25-4526ba91be46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Follow the above document and insert/update/delete data from salesforce and see whether following things are working seamlessly\n",
    "--1. CDC (Change Data Capture) - Related more towards capturing data from source\n",
    "--2. SCD1 (Slowly Changing Dimension 1) implemented naturally. - Related more towards how we are writing the changed data from source, either doing just ins/upd/del or only inserting and deactivating flags (scd2)\n",
    "select * from catalog3_we47.default.contact;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8752156577565675,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "lakeflow_ingestion_native_salesforce_connector_3.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
